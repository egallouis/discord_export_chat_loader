import json
from abc import abstractmethod
from datetime import timedelta, datetime
from os import PathLike
from pathlib import Path
from typing import Iterator, Union, Dict, Any, List

from langchain_core.document_loaders import BaseLoader
from langchain_core.documents import Document


class BaseDiscordJSONLoader(BaseLoader):
    @abstractmethod
    def __init__(self, file_path: Union[str, PathLike],
                 encoding: str = "utf-8") -> None:
        """
        Initialize the loader with the filepath of the JSON file and the number of messages in one document.
        :param file_path: Path to the JSON file.
        :param encoding: Encoding of the JSON file. You can find supported encodings here: https://docs.python.org/3.12/library/codecs.html#standard-encodings
        """
        self.file_path = Path(file_path).resolve()
        self.encoding = encoding

    @staticmethod
    def _format_message(msg: Dict[str, Any]) -> str:
        """
        Formats a single Discord message into a textual representation with the name of the author and the timestamp.
        :param msg: The dict of a JSON Discord message.
        :return: A string containing the name of the author, the timestamp of the message and the content.
        """
        name = msg.get("author", {}).get("name", "Unknown Author")
        timestamp = msg.get("timestamp", "Unknown Timestamp")
        content = msg.get("content", "")

        return f"{name} wrote at {timestamp}: {content}"

    def _safe_load_json(self) -> list[dict]:
        """
        Safely loads a JSON file generated from Tyrrrz/DiscordChatExporter.
        Reports Errors and then returns [] if anything goes wrong.
        :return: List[dict] containing message information
        """
        try:
            file_content = self.file_path.read_text(encoding="utf-8")
            data = json.loads(file_content)
        except FileNotFoundError:
            print(f"Error: File not found at {self.file_path}")
            return []
        except json.JSONDecodeError:
            print(f"Error: Could not decode JSON from {self.file_path}")
            return []
        except Exception as e:
            print(f"Error loading file {self.file_path}: {e}")
            return []

        messages = data.get("messages")
        if not isinstance(messages, list):
            print(f"Error: Expected a 'messages' key with a list value in {self.file_path}")
            return []
        return messages


class DiscordJSONLoader(BaseDiscordJSONLoader):
    """
    Load a JSON file generated by https://github.com/Tyrrrz/DiscordChatExporter.

    This loader processes the JSON file, extracts and formats messages,
    grouping them into chunks of a specified size. Each chunk is returned as a LangChain Document object.
    If the number remaining documents are smaller than chunk_size, they will be returned as their own Document.

    Example:
        loader = DiscordJSONLoader(file_path="path/to/discord_messages.json", chunk_size=20, chunk_overlap=5)
        documents = loader.load() # Or iterate with loader.lazy_load()

    Args:
        file_path (Union[str, PathLike]): Path to the JSON file.
        chunk_size (int): Number of consecutive messages to group into one Document. Default is 10.
        chunk_overlap (int): Number of messages shared by two consecutive Documents. Default is 0.
        encoding (str): File encoding used by pythons json module to decode the JSON file.
    """

    def __init__(self, file_path: Union[str, PathLike], chunk_size: int = 10, chunk_overlap: int = 0,
                 encoding: str = "utf-8") -> None:
        """
        Initialize the loader with the filepath of the JSON file and the number of messages in one document.
        :param file_path: Path to the JSON file.
        :param chunk_size: Number of messages in a document.
        :param chunk_overlap: Number of messages to overlap between documents.
        :param encoding: Encoding of the JSON file. You can find supported encodings here: https://docs.python.org/3.12/library/codecs.html#standard-encodings
        """
        super().__init__(file_path, encoding)

        if chunk_size <= 0:
            raise ValueError("chunk_size must be a positive integer.")
        self.chunk_size = chunk_size

        if chunk_overlap < 0:
            raise ValueError("chunk_overlap must be a positive integer or 0.")
        if chunk_overlap >= self.chunk_size:
            raise ValueError("chunk_overlap must be smaller than chunk_size ")
        self.chunk_overlap = chunk_overlap

    def lazy_load(self) -> Iterator[Document]:
        """
        Generator that yield Documents from exported Discord messages
        :return: Iterator[Document]: yielding Documents, as long as there are messages left.
        """
        messages = self._safe_load_json()

        in_chunk_formatted_messages: List[str] = []
        seq_num = 0

        # Keep track of original message index for metadata
        start_msg_idx = 0

        i = 0
        while i < len(messages):
            msg_data = messages[i]
            formatted_msg = self._format_message(msg_data)

            in_chunk_formatted_messages.append(formatted_msg)

            # Build Document, if the group is full
            if len(in_chunk_formatted_messages) >= self.chunk_size:
                text = "\n".join(in_chunk_formatted_messages)
                metadata = {
                    "source": str(self.file_path),  # Use string representation
                    "seq_num": seq_num,
                    "start_message_index": start_msg_idx,
                    "end_message_index": i
                }
                yield Document(page_content=text, metadata=metadata)

                # Reset for the next group
                in_chunk_formatted_messages = []
                seq_num += 1

                # Reset index to include overlapping messages in the next document
                i -= self.chunk_overlap

                # Next group starts after this message index
                start_msg_idx = i + 1

            i += 1

        # Yield the last remaining group (if any)
        if in_chunk_formatted_messages:
            text = "\n".join(in_chunk_formatted_messages)
            metadata = {
                "source": str(self.file_path),
                "seq_num": seq_num,
                "start_message_index": start_msg_idx,
                "end_message_index": len(messages) - 1  # Ends with the last processed message
            }
            yield Document(page_content=text, metadata=metadata)


class TimeWindowDiscordJSONLoader(BaseDiscordJSONLoader):
    """
    Load a JSON file generated by https://github.com/Tyrrrz/DiscordChatExporter.

    This loader processes the JSON file, extracts and formats messages,
    grouping them into chunks of messages sent in a specific timeframe.

    Example:
        loader = TimeWindowDiscordJSONLoader(file_path="path/to/discord_messages.json", chunk_timeframe=timedelta(hours=1))
        documents = loader.load() # Or iterate with loader.lazy_load()

    Args:
        file_path (Union[str, PathLike]): Path to the JSON file.
        chunk_timeframe (timedelta): Number of consecutive messages to group into one Document. Default is 10.
        chunk_overlap (timedelta): Number of messages shared by two consecutive Documents. Default is 0.
        encoding (str): File encoding used by pythons json module to decode the JSON file.
    """

    def __init__(self, file_path: Union[str, PathLike], chunk_timeframe: timedelta = timedelta(hours=1),
                 chunk_overlap: timedelta = timedelta(), encoding: str = "utf-8") -> None:
        """
        Initialize the loader with the filepath of the JSON file and the number of messages in one document.
        :param file_path: Path to the JSON file.
        :param chunk_timeframe: Number of messages in a document.
        :param chunk_overlap: Number of messages to overlap between documents.
        :param encoding: Encoding of the JSON file. You can find supported encodings here: https://docs.python.org/3.12/library/codecs.html#standard-encodings
        """
        super().__init__(file_path, encoding)

        if chunk_timeframe.total_seconds() <= 0:
            raise ValueError("chunk_timeframe must be a positive timedelta.")
        self.chunk_timeframe = chunk_timeframe

        if chunk_overlap.total_seconds() < 0:
            raise ValueError("chunk_overlap must be a positive timedelta. or 0")
        if chunk_overlap >= self.chunk_timeframe:
            raise ValueError("chunk_overlap must be smaller than chunk_size ")
        self.chunk_overlap = chunk_overlap

    def lazy_load(self) -> Iterator[Document]:
        """
        Generator that yield Documents from exported Discord messages
        :return: Iterator[Document]: yielding Documents, as long as there are messages left.
        """
        messages = self._safe_load_json()

        in_chunk_formatted_messages: List[str] = []
        seq_num = 0

        # Keep track of original message index for metadata
        start_msg_time = datetime.fromisoformat(messages[0]["timestamp"])

        i = 0
        while i < len(messages):
            msg_data = messages[i]
            formatted_msg = self._format_message(msg_data)

            in_chunk_formatted_messages.append(formatted_msg)

            current_msg_time = datetime.fromisoformat(msg_data["timestamp"])

            # Build Document, if the group is full
            if current_msg_time >= start_msg_time + self.chunk_timeframe:
                text = "\n".join(in_chunk_formatted_messages)
                metadata = {
                    "source": str(self.file_path),  # Use string representation
                    "seq_num": seq_num,
                    "start_message_time": str(start_msg_time),
                    "end_message_index": str(current_msg_time)
                }
                yield Document(page_content=text, metadata=metadata)

                # Reset for the next group
                in_chunk_formatted_messages = []
                seq_num += 1

                # Reset index to include overlapping messages in the next document
                new_start_time = current_msg_time - self.chunk_overlap

                # Find new start index, immediately before overlap time
                while datetime.fromisoformat(messages[i]["timestamp"]) >= new_start_time:
                    i -= 1

                # Next group starts after this message index
                start_msg_time = datetime.fromisoformat(messages[i + 1]["timestamp"])

            i += 1

        # Yield the last remaining group (if any)
        if in_chunk_formatted_messages:
            text = "\n".join(in_chunk_formatted_messages)
            metadata = {
                "source": str(self.file_path),
                "seq_num": seq_num,
                "start_message_time": str(start_msg_time),
                "end_message_index": datetime.fromisoformat(messages[-1]["timestamp"])
            }
            yield Document(page_content=text, metadata=metadata)
